{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import CNN2Head_input2 as CNN2Head_input\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import BKNetStyle2 as BKNetStyle\n",
    "from const import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load smile image...................\n",
      "Done !\n",
      "Number of smile train data:  3000\n",
      "---------------------------------------------------------------\n",
      "Load gender image...................\n",
      "Done !\n",
      "Number of gender train data:  96000\n",
      "---------------------------------------------------------------\n",
      "Load age image...................\n",
      "Done !\n",
      "Number of age train data:  96000\n",
      "---------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "''' PREPARE DATA '''\n",
    "''' PREPARE DATA '''\n",
    "smile_train, smile_test = CNN2Head_input.getSmileImage()\n",
    "gender_train, gender_test = CNN2Head_input.getGenderImage()\n",
    "age_train, age_test = CNN2Head_input.getAgeImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654\n",
      "33221\n",
      "33221\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(smile_test))\n",
    "print(len(gender_test))\n",
    "print(len(age_test))\n",
    "print(DECAY_STEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(index, num_classes):\n",
    "    assert index < num_classes and index >= 0\n",
    "    tmp = np.zeros(num_classes, dtype=np.float32)\n",
    "    tmp[index] = 1.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-f3b231242595>:2: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "x, y_, mask = BKNetStyle.Input()\n",
    "y_smile_conv, y_gender_conv, y_age_conv, phase_train, keep_prob = BKNetStyle.BKNetModel(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n",
      "Create new model\n",
      "OK\n",
      "Epoch: 1\n",
      "Learning rate: 0.010000\n",
      "Training on batch 1000/1734\n",
      "Smile task train accuracy: 83.38556948519606\n",
      "Gender task train accuracy: 81.4643091574023\n",
      "Age task train error: 23.746819\n",
      "Smile loss: 0.44061166\n",
      "Gender loss: 0.44948837\n",
      "Age loss: 4.0419455\n",
      "Total loss: 5.683907. L2-loss: 0.75186163\n",
      "\n",
      "\n",
      "Epoch: 2\n",
      "Learning rate: 0.010000\n",
      "Training on batch 1000/1734\n",
      "Smile task train accuracy: 91.29043014338113\n",
      "Gender task train accuracy: 86.5926211488169\n",
      "Age task train error: 23.729975\n",
      "Smile loss: 0.3214132\n",
      "Gender loss: 0.3728076\n",
      "Age loss: 3.963524\n",
      "Total loss: 5.016013. L2-loss: 0.35826778\n",
      "\n",
      "\n",
      "Epoch: 3\n",
      "Learning rate: 0.009500\n",
      "Training on batch 1000/1734\n",
      "Smile task train accuracy: 92.08868144690781\n",
      "Gender task train accuracy: 87.20801817007356\n",
      "Age task train error: 23.71479\n",
      "Smile loss: 0.30412948\n",
      "Gender loss: 0.36167595\n",
      "Age loss: 3.9354455\n",
      "Total loss: 4.95105. L2-loss: 0.34979847\n",
      "\n",
      "\n",
      "Epoch: 4\n",
      "Learning rate: 0.009500\n",
      "Training on batch 1000/1734\n",
      "Smile task train accuracy: 92.6913843691651\n",
      "Gender task train accuracy: 87.64547149956762\n",
      "Age task train error: 23.703087\n",
      "Smile loss: 0.28748268\n",
      "Gender loss: 0.35309085\n",
      "Age loss: 3.916551\n",
      "Total loss: 4.9108706. L2-loss: 0.35374624\n",
      "\n",
      "\n",
      "Epoch: 5\n",
      "Learning rate: 0.009025\n",
      "Training on batch 1000/1734\n",
      "Smile task train accuracy: 92.90834528056547\n",
      "Gender task train accuracy: 87.93423218788422\n",
      "Age task train error: 23.670803\n",
      "Smile loss: 0.28477466\n",
      "Gender loss: 0.34857315\n",
      "Age loss: 3.9004726\n",
      "Total loss: 4.89257. L2-loss: 0.35875005\n",
      "\n",
      "\n",
      "Epoch: 6\n",
      "Learning rate: 0.009025\n"
     ]
    }
   ],
   "source": [
    "smile_loss, gender_loss, age_loss, l2_loss, loss = BKNetStyle.selective_loss(y_smile_conv, y_gender_conv,\n",
    "                                                                             y_age_conv, y_, mask)\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "    \n",
    "train_step = BKNetStyle.train_op(loss, global_step)\n",
    "\n",
    "smile_mask = tf.get_collection('smile_mask')[0]\n",
    "gender_mask = tf.get_collection('gender_mask')[0]\n",
    "age_mask = tf.get_collection('age_mask')[0]\n",
    "\n",
    "y_smile = tf.get_collection('y_smile')[0]\n",
    "y_gender = tf.get_collection('y_gender')[0]\n",
    "y_age = tf.get_collection('y_age')[0]\n",
    "\n",
    "smile_correct_prediction = tf.equal(tf.argmax(y_smile_conv, 1), tf.argmax(y_smile, 1))\n",
    "gender_correct_prediction = tf.equal(tf.argmax(y_gender_conv, 1), tf.argmax(y_gender, 1))\n",
    "# age_correct_prediction = tf.equal(tf.argmax(y_age_conv, 1), tf.argmax(y_age, 1))\n",
    "\n",
    "smile_true_pred = tf.reduce_sum(tf.cast(smile_correct_prediction, dtype=tf.float32) * smile_mask)\n",
    "gender_true_pred = tf.reduce_sum(tf.cast(gender_correct_prediction, dtype=tf.float32) * gender_mask)\n",
    "# age_true_pred = tf.reduce_sum(tf.cast(age_correct_prediction, dtype=tf.float32) * age_mask)\n",
    "age_mae, update_op = tf.metrics.mean_absolute_error(\n",
    "    tf.argmax(y_age, 1), tf.argmax(y_age_conv, 1), name=\"age_mae\")\n",
    "running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope=\"age_mae\")\n",
    "running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "sess.run(running_vars_initializer)\n",
    "\n",
    "train_data = []\n",
    "# Mask: Smile -> 0, Gender -> 1, Age -> 2\n",
    "for i in range(len(smile_train) * 10):\n",
    "    img = (smile_train[i % 3000][0] - 128) / 255.0\n",
    "    label = smile_train[i % 3000][1]\n",
    "    train_data.append((img, one_hot(label, 101), 0.0))\n",
    "for i in range(len(gender_train)):\n",
    "    img = (gender_train[i][0] - 128) / 255.0\n",
    "    label = (int)(gender_train[i][1])\n",
    "    train_data.append((img, one_hot(label, 101), 1.0))\n",
    "for i in range(len(age_train)):\n",
    "    img = (age_train[i][0] - 128) / 255.0\n",
    "    label = (int)(age_train[i][1])\n",
    "    train_data.append((img, one_hot(label, 101), 2.0))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if not os.path.isfile(SAVE_FOLDER3 + 'model-age101.ckpt.index'):\n",
    "    print('Create new model')\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print('OK')\n",
    "else:\n",
    "    print('Restoring existed model')\n",
    "    saver.restore(sess, SAVE_FOLDER3 + 'model-age101.ckpt')\n",
    "    print('OK')\n",
    "\n",
    "loss_summary_placeholder = tf.placeholder(tf.float32)\n",
    "tf.summary.scalar('loss', loss_summary_placeholder)\n",
    "merge_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"./summary3/\", graph=tf.get_default_graph())\n",
    "\n",
    "learning_rate = tf.get_collection('learning_rate')[0]\n",
    "current_epoch = (int)(global_step.eval() / (len(train_data) // BATCH_SIZE))\n",
    "for epoch in range(current_epoch + 1, NUM_EPOCHS):\n",
    "    print('Epoch:', str(epoch))\n",
    "    np.random.shuffle(train_data)\n",
    "    train_img = []\n",
    "    train_label = []\n",
    "    train_mask = []\n",
    "\n",
    "    for i in range(len(train_data)):\n",
    "        train_img.append(train_data[i][0])\n",
    "        train_label.append(train_data[i][1])\n",
    "        train_mask.append(train_data[i][2])\n",
    "\n",
    "    number_batch = len(train_data) // BATCH_SIZE\n",
    "\n",
    "    avg_ttl = []\n",
    "    avg_rgl = []\n",
    "    avg_smile_loss = []\n",
    "    avg_gender_loss = []\n",
    "    avg_age_loss = []\n",
    "\n",
    "    smile_nb_true_pred = 0\n",
    "    gender_nb_true_pred = 0\n",
    "    age_nb_true_pred = 0\n",
    "\n",
    "    smile_nb_train = 0\n",
    "    gender_nb_train = 0\n",
    "    age_nb_train = 0\n",
    "\n",
    "    print(\"Learning rate: %f\" % learning_rate.eval())\n",
    "#     for batch in range(number_batch):\n",
    "    for batch in range(number_batch):\n",
    "        if (batch+1)%1000==0:\n",
    "            print('Training on batch {0}/{1}'.format(str(batch + 1), str(number_batch)))\n",
    "        top = batch * BATCH_SIZE\n",
    "        bot = min((batch + 1) * BATCH_SIZE, len(train_data))\n",
    "        batch_img = np.asarray(train_img[top:bot])\n",
    "        batch_label = np.asarray(train_label[top:bot])\n",
    "        batch_mask = np.asarray(train_mask[top:bot])\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if batch_mask[i] == 0.0:\n",
    "                smile_nb_train += 1\n",
    "            else:\n",
    "                if batch_mask[i] == 1.0:\n",
    "                    gender_nb_train += 1                        \n",
    "                else:\n",
    "                    age_nb_train += 1\n",
    "\n",
    "        batch_img = CNN2Head_input.augmentation(batch_img, 48)\n",
    "\n",
    "        ttl, sml, gel, agl, l2l, _ = sess.run([loss, smile_loss, gender_loss, age_loss, l2_loss, train_step],\n",
    "                                              feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                         phase_train: True,\n",
    "                                                         keep_prob: 0.5})\n",
    "\n",
    "        smile_nb_true_pred += sess.run(smile_true_pred, feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                                   phase_train: True,\n",
    "                                                                   keep_prob: 0.5})\n",
    "\n",
    "        gender_nb_true_pred += sess.run(gender_true_pred,\n",
    "                                        feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                   phase_train: True,\n",
    "                                                   keep_prob: 0.5})\n",
    "\n",
    "#         age_nb_true_pred += sess.run(age_true_pred,\n",
    "#                                          feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "#                                                     phase_train: True,\n",
    "#                                                     keep_prob: 0.5})\n",
    "\n",
    "        sess.run(update_op,\n",
    "            feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                       phase_train: False,\n",
    "                       keep_prob: 1})\n",
    "\n",
    "        '''--------------------------------------- DEBUG -----------------------------------------------------'''\n",
    "        '''\n",
    "        sm_mask, em_mask, ge_mask = sess.run([smile_mask, gender_mask, age_mask],\n",
    "                                             feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                        phase_train: True,\n",
    "                                                        keep_prob: 0.5})\n",
    "        print('Smile mask: ', sm_mask)\n",
    "        print('Gender mask', ge_mask)\n",
    "        print('Age mask', ag_mask)\n",
    "        print('Batch mask', batch_mask)\n",
    "\n",
    "        y_true_sm, y_true_ge, y_true_ag = sess.run([y_smile, y_gender, y_age],\n",
    "                                                   feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                              phase_train: True,\n",
    "                                                              keep_prob: 0.5})\n",
    "        print('Smile label', y_true_sm)\n",
    "        print('Gender label', y_true_ge)\n",
    "        print('Age label', y_true_ag)\n",
    "        print('Batch label', batch_label)\n",
    "\n",
    "        y_conv_sm, y_conv_ge, y_conv_ag = sess.run([y_smile_conv, y_gender_conv, y_age_conv],\n",
    "                                                   feed_dict={x: batch_img, y_: batch_label, mask: batch_mask,\n",
    "                                                              phase_train: True,\n",
    "                                                              keep_prob: 0.5})\n",
    "        print('Smile conv', y_conv_sm)\n",
    "        print('Gender conv', y_conv_ge)\n",
    "        print('Age conv', y_conv_ag)\n",
    "\n",
    "        '''\n",
    "        '''---------------------------------- END OF DEBUG ----------------------------------------------------'''\n",
    "\n",
    "        avg_ttl.append(ttl)\n",
    "        avg_smile_loss.append(sml)\n",
    "        avg_gender_loss.append(gel)\n",
    "        avg_age_loss.append(agl)\n",
    "\n",
    "        avg_rgl.append(l2l)\n",
    "\n",
    "    smile_train_accuracy = smile_nb_true_pred * 1.0 / smile_nb_train\n",
    "    gender_train_accuracy = gender_nb_true_pred * 1.0 / gender_nb_train\n",
    "    age_train_accuracy = age_nb_true_pred * 1.0 / age_nb_train\n",
    "\n",
    "    avg_smile_loss = np.average(avg_smile_loss)\n",
    "    avg_gender_loss = np.average(avg_gender_loss)\n",
    "    avg_age_loss = np.average(avg_age_loss)\n",
    "\n",
    "    avg_rgl = np.average(avg_rgl)\n",
    "    avg_ttl = np.average(avg_ttl)\n",
    "\n",
    "    summary = sess.run(merge_summary, feed_dict={loss_summary_placeholder: avg_ttl})\n",
    "    writer.add_summary(summary, global_step=epoch)\n",
    "\n",
    "    with open('log2.csv', 'a') as f:\n",
    "        # epochs, smile_train_accuracy, gender_train_accuracy, age_train_accuracy,\n",
    "        # avg_smile_loss, avg_gender_loss, avg_age_loss, avg_ttl, avg_rgl\n",
    "        f.write('{0},{1},{2},{3},{4},{5},{6},{7},{8}\\n'.format(current_epoch, smile_train_accuracy, gender_train_accuracy, age_train_accuracy, avg_smile_loss, avg_gender_loss, avg_age_loss, avg_ttl, avg_rgl))\n",
    "\n",
    "    print('Smile task train accuracy: ' + str(smile_train_accuracy * 100))\n",
    "    print('Gender task train accuracy: ' + str(gender_train_accuracy * 100))\n",
    "    age_train_error = sess.run(age_mae)\n",
    "    print('Age task train error: ' + str(age_train_error))\n",
    "\n",
    "    print('Smile loss: ' + str(avg_smile_loss))\n",
    "    print('Gender loss: ' + str(avg_gender_loss))\n",
    "    print('Age loss: ' + str(avg_age_loss))\n",
    "    print('Total loss: ' + str(avg_ttl) + '. L2-loss: ' + str(avg_rgl))\n",
    "\n",
    "    print('\\n')\n",
    "    \n",
    "    saver.save(sess, SAVE_FOLDER3 + 'model-age101.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
