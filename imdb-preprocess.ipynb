{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB-WIKI\n",
    "##  Multi-task age and gender classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the original paper [DEX: Deep EXpectation of apparent age from a single image](https://www.vision.ee.ethz.ch/en/publications/papers/proceedings/eth_biwi_01229.pdf) the authors were able to display remarkable results in classifying the age of an individual based on a given image alone. \n",
    "\n",
    "Let see how accuracy (bad I guess), with limited resources, we can get with self-construct architecture. And not only age, we also classifying gender by using multi-task training technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.misc as spm\n",
    "from scipy import ndimage\n",
    "import datetime\n",
    "import matplotlib.image as plt\n",
    "from IPython.display import Image, display\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "from collections import Counter\n",
    "# from skimage.transform import resize\n",
    "\n",
    "IMG_DIR = r'/home/truongnmt/coding/cnn/datasets/imdb_crop'\n",
    "MAT_FILE = r'/home/truongnmt/coding/cnn/datasets/imdb_crop/imdb.mat'\n",
    "\n",
    "img_depth = 1\n",
    "img_size = 128\n",
    "num_classes = 2\n",
    "\n",
    "max_bytes = 2**31 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the labels, which was not easily obtained. The meta data is stored separately and in a .mat file. (Yes, matlab)!\n",
    "\n",
    "The age parameter, requires us to calculate by taking the ```photo_taken``` and subtracting the ```dob```, the date of birth. Sounds easy? No ... as the dob is stored as a Matlab serial number.\n",
    "\n",
    "Luckily we can use the ```scipy.io.loadmat``` to load the ```.mat``` file to python accessible (kind of) format. We can access the ```dob``` by some proper indexing, and convert the Matlab serial number to a usable format by using ```datetime.date.fromordinal( serial_number ).year```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_date(mat_date):\n",
    "    dt = datetime.date.fromordinal(np.max([mat_date - 366, 1])).year\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(path):\n",
    "    return os.path.join(IMG_DIR, path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary created...\n"
     ]
    }
   ],
   "source": [
    "mat_struct = sio.loadmat(MAT_FILE)\n",
    "data_set = [data[0] for data in mat_struct['imdb'][0, 0]]\n",
    "\n",
    "keys = ['dob',\n",
    "    'photo_taken',\n",
    "    'full_path',\n",
    "    'gender',\n",
    "    'name',\n",
    "    'face_location',\n",
    "    'face_score',\n",
    "    'second_face_score',\n",
    "    'celeb_names',\n",
    "    'celeb_id'\n",
    "]\n",
    "\n",
    "imdb_dict = dict(zip(keys, np.asarray(data_set)))\n",
    "imdb_dict['dob'] = [reformat_date(dob) for dob in imdb_dict['dob']]\n",
    "imdb_dict['full_path'] = [create_path(path) for path in imdb_dict['full_path']]\n",
    "\n",
    "# Add 'age' key to the dictionary\n",
    "imdb_dict['age'] = imdb_dict['photo_taken'] - imdb_dict['dob']\n",
    "\n",
    "print(\"Dictionary created...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IMDB dataset has total 460,723 face images from 20,284 celebrities. \n",
    "\n",
    "We will ignore:\n",
    "* images with more than one face\n",
    "* gender is NaN\n",
    "* invalid age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dict['age'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 of 460723\n",
      "Second face score: 1.11897335716\n",
      "Age: 69\n",
      "Gender: 1.0\n",
      "Processing 200000 of 460723\n",
      "Second face score: nan\n",
      "Age: 55\n",
      "Gender: 1.0\n",
      "Processing 400000 of 460723\n",
      "Second face score: nan\n",
      "Age: 27\n",
      "Gender: 0.0\n"
     ]
    }
   ],
   "source": [
    "raw_path = imdb_dict['full_path']\n",
    "raw_age = imdb_dict['age']\n",
    "raw_gender = imdb_dict['gender']\n",
    "raw_sface = imdb_dict['second_face_score']\n",
    "\n",
    "age = []\n",
    "gender = []\n",
    "imgs = []\n",
    "for i, sface in enumerate(raw_sface):\n",
    "    age_tmp = 0;\n",
    "    if i%200000==0:\n",
    "        print(\"Processing {0} of {1}\".format(i,len(raw_sface)))\n",
    "        #         display(Image(filename=raw_path[i]))\n",
    "        print(\"Second face score: {}\".format(sface))\n",
    "        print(\"Age: {}\".format(raw_age[i]))\n",
    "        print(\"Gender: {}\".format(raw_gender[i]))\n",
    "    if np.isnan(sface) and raw_age[i] >= 0 and not np.isnan(raw_gender[i]):\n",
    "        if len(age)==170000:\n",
    "            break\n",
    "        counts = Counter(age)\n",
    "        if raw_age[i] < 30 and counts[0] <  42500:\n",
    "            age_tmp = 0\n",
    "        elif raw_age[i] <= 45 and counts[1] < 42500:\n",
    "            age_tmp = 1\n",
    "        elif raw_age[i] < 60 and counts[2] < 42500:\n",
    "            age_tmp = 2\n",
    "        elif raw_age[i] >= 60 and counts[3] < 42500:\n",
    "            age_tmp = 3\n",
    "        else:\n",
    "            continue\n",
    "        age.append(age_tmp)\n",
    "        gender.append(raw_gender[i])\n",
    "        imgs.append(raw_path[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(age)\n",
    "print(counts)\n",
    "print(counts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some photos are colored and some are gray scale, while the sizes are not consistent. Moreover, processing file in RBG format is too big, when attemp to save objects to pickle file, 60000 file is equivalent to 11GB. So we gonna resize image to 128x128, convert to grayscale.\n",
    "\n",
    "Also due to limit of resources and time, I only pick first ```100000``` images to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting images path to images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/truongnmt/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/home/truongnmt/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size: 460723 - Preprocess size: 100000\n"
     ]
    }
   ],
   "source": [
    "# Convert images path to images.\n",
    "\n",
    "# only take a subset of dataset: first 10000 imgs\n",
    "# dataset = np.ndarray(shape=(100000, img_size, img_size, img_depth), dtype=np.float32)\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"/pkl_folder/imdb_data_train.pkl\") and os.path.exists(\n",
    "    os.getcwd()+\"/pkl_folder/imdb_data_valid.pkl\") and os.path.exists(\n",
    "    os.getcwd()+\"/pkl_folder/imdb_data_test.pkl\"):\n",
    "    print(\"Dataset already present - Skip convert images to images.\")\n",
    "else:\n",
    "    print(\"Converting images path to images.\")\n",
    "    real_imgs = []\n",
    "    tmp = []\n",
    "    for i, img_path in enumerate(imgs):\n",
    "        if i==100000:\n",
    "            break\n",
    "        tmp = np.asarray(spm.imresize(spm.imread(img_path, flatten=1), (128, 128)), dtype=np.float32)\n",
    "        real_imgs.append(tmp)\n",
    "\n",
    "    print(\"Original size: {0} - Preprocess size: {1}\".format(len(raw_sface), len(real_imgs)))\n",
    "    \n",
    "#     print(\"Converting images path to images.\")\n",
    "#     for i, img_path in enumerate(imgs):\n",
    "#         if i == 100000:\n",
    "#             break\n",
    "#         image_data = resize(((ndimage.imread(img_path).astype(float) - img_depth / 2) / img_depth), \n",
    "#                             (img_size, img_size, img_depth), mode='reflect')\n",
    "#         dataset[i, :, :, :] = image_data\n",
    "\n",
    "#     print(\"Original size: {0} - Preprocess size: {1}\".format(len(raw_sface), len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump 3 datasets to pickles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be63ad63d972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdata_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_valid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-be63ad63d972>\u001b[0m in \u001b[0;36mcreate_pickle\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdump_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdump_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_valid_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mdump_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-be63ad63d972>\u001b[0m in \u001b[0;36mdump_data\u001b[0;34m(file_path, slice_from, slice_to)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdump_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     data = {'image_inputs': np.array(real_imgs[slice_from:slice_to]),\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0;34m'age_labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mslice_to\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0;34m'gender_labels'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslice_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mslice_to\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             }\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def dump_data(file_path, slice_from, slice_to):\n",
    "    data = {'image_inputs': np.array(real_imgs[slice_from:slice_to]),\n",
    "            'age_labels': np.array(age[slice_from:slice_to]),\n",
    "            'gender_labels': np.array(gender[slice_from:slice_to])\n",
    "            }\n",
    "    print(\"Dataset dump size: {}\".format(len(data['image_inputs'])))\n",
    "    with open(file_path,'wb') as f:\n",
    "        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n",
    "    print(\"Dumped to {}\".format(file_path))\n",
    "\n",
    "def create_pickle(force=False):\n",
    "    data_train_path = os.getcwd()+\"/pkl_folder/imdb_data_train.pkl\"\n",
    "    data_valid_path = os.getcwd()+\"/pkl_folder/imdb_data_valid.pkl\"\n",
    "    data_test_path = os.getcwd()+\"/pkl_folder/imdb_data_test.pkl\"\n",
    "    if os.path.exists(data_train_path) and os.path.exists(\n",
    "        data_valid_path) and os.path.exists(\n",
    "        data_test_path) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print(\"Dataset already present - Skip pickling.\")\n",
    "        \n",
    "    else:\n",
    "        dump_data(data_train_path, 0, 60000)\n",
    "        dump_data(data_valid_path, 60000, 80000)\n",
    "        dump_data(data_test_path, 80000, 1000000)\n",
    "\n",
    "    return data_train_path, data_valid_path, data_test_path\n",
    "\n",
    "data_train_path, data_valid_path, data_test_path = create_pickle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are using only a subset of the data, and also using a self-constructed model that has a much smaller capacity, thus we need to take steps to adjust accordingly.\n",
    "\n",
    "The original paper uses 101101 age classes, which was appropriate for the their data set size and learning architecture. As we are only using a small subset of the data and a very simple model, the number of classes was set to 4:\n",
    "* Young    (30yrs < age)\n",
    "* Middle   (30 <= age <45)\n",
    "* Old      (45 <= age < 60)\n",
    "* Very Old (60 <= age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            data_train = pickle.load(f)\n",
    "            labels = np.ndarray((len(data_train['image_inputs']), num_classes), dtype=np.int32)\n",
    "            dataset = np.ndarray((len(data_train['image_inputs']), img_size, img_size, img_depth), dtype=np.float32)\n",
    "            # let's shuffle to have random dataset\n",
    "            np.random.shuffle(dataset)\n",
    "            dataset = data_train['image_inputs']\n",
    "            for i, age_label in enumerate(data_train['age_labels']):\n",
    "                if i==len(data_train['image_inputs']):\n",
    "                    break\n",
    "                if age_label < 30:\n",
    "                    age = 0\n",
    "                elif age_label <= 45:\n",
    "                    age = 1\n",
    "                elif age_label < 60:\n",
    "                    age = 2\n",
    "                elif age_label >= 60:\n",
    "                    age = 3\n",
    "                else:\n",
    "                    continue\n",
    "                labels[i,:] = np.array([age, data_train['gender_labels'][i]])\n",
    "            return dataset, labels\n",
    "            \n",
    "    except Exception as e:\n",
    "        print('Unable to process data from', pickle_file, ':', e)\n",
    "        raise\n",
    "\n",
    "train_dataset, train_labels = convert_label(data_train_path)\n",
    "valid_dataset, valid_labels = convert_label(data_valid_path)\n",
    "test_dataset, test_labels = convert_label(data_test_path)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Validation:', valid_dataset.shape, valid_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll randomize the data. It's important to have the labels well shuffled for the training and test distributions to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, train_labels = randomize(train_dataset, train_labels)\n",
    "test_dataset, test_labels = randomize(test_dataset, test_labels)\n",
    "valid_dataset, valid_labels = randomize(valid_dataset, valid_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat into a TensorFlow-friendly shape:\n",
    "* convolutions need the image data formatted as a cube (width by height by channels)\n",
    "* labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = img_depth # = 1 (Grayscale)\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape(\n",
    "        (-1, img_size, img_size, num_channels)).astype(np.float32)\n",
    "    one_hot_labels = np.ndarray((len(labels), 2, 4), dtype=np.float32)\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot_age = (np.arange(4)==label[0]).astype(np.float32)\n",
    "        one_hot_gender = (np.arange(4)==label[1]).astype(np.float32)\n",
    "        one_hot_labels[i,:,:] = np.array([one_hot_age, one_hot_gender])\n",
    "#     labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "    return dataset, one_hot_labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to final pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = 'imdb.pkl'\n",
    "\n",
    "try:\n",
    "    f = open(os.getcwd()+\"/pkl_folder/\"+pickle_file, 'wb')\n",
    "    save = {\n",
    "    'train_dataset': train_dataset,\n",
    "    'train_labels': train_labels,\n",
    "    'valid_dataset': valid_dataset,\n",
    "    'valid_labels': valid_labels,\n",
    "    'test_dataset': test_dataset,\n",
    "    'test_labels': test_labels,\n",
    "    }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise\n",
    "\n",
    "statinfo = os.stat(os.getcwd()+\"/pkl_folder/\"+pickle_file)\n",
    "print('Compressed pickle size:', statinfo.st_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
