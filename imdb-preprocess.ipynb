{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from six.moves import cPickle as pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.misc as spm\n",
    "from scipy import ndimage\n",
    "import datetime\n",
    "import matplotlib.image as plt\n",
    "from IPython.display import Image, display\n",
    "from skimage.transform import resize\n",
    "\n",
    "IMG_DIR = r'/home/ubuntu/coding/cnn/datasets/imdb_crop'\n",
    "MAT_FILE = r'/home/ubuntu/coding/cnn/datasets/imdb_crop/imdb.mat'\n",
    "\n",
    "img_depth = 3\n",
    "img_size = 128\n",
    "\n",
    "n_bytes = 2**31\n",
    "max_bytes = 2**31 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_date(mat_date):\n",
    "    dt = datetime.date.fromordinal(np.max([mat_date - 366, 1])).year\n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path(path):\n",
    "    return os.path.join(IMG_DIR, path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary created...\n"
     ]
    }
   ],
   "source": [
    "mat_struct = sio.loadmat(MAT_FILE)\n",
    "data_set = [data[0] for data in mat_struct['imdb'][0, 0]]\n",
    "\n",
    "keys = ['dob',\n",
    "    'photo_taken',\n",
    "    'full_path',\n",
    "    'gender',\n",
    "    'name',\n",
    "    'face_location',\n",
    "    'face_score',\n",
    "    'second_face_score',\n",
    "    'celeb_names',\n",
    "    'celeb_id'\n",
    "]\n",
    "\n",
    "imdb_dict = dict(zip(keys, np.asarray(data_set)))\n",
    "imdb_dict['dob'] = [reformat_date(dob) for dob in imdb_dict['dob']]\n",
    "imdb_dict['full_path'] = [create_path(path) for path in imdb_dict['full_path']]\n",
    "\n",
    "# Add 'age' key to the dictionary\n",
    "imdb_dict['age'] = imdb_dict['photo_taken'] - imdb_dict['dob']\n",
    "\n",
    "print(\"Dictionary created...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 0 samples. (0=all samples)\n",
      "Processing 0 of 460723\n",
      "Second face score: 1.1189733571573068 Age: 69 Gender: 1.0\n",
      "Processing 200000 of 460723\n",
      "Second face score: nan Age: 55 Gender: 1.0\n",
      "Processing 400000 of 460723\n",
      "Second face score: nan Age: 27 Gender: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting {} samples. (0=all samples)\".format(0))\n",
    "\n",
    "raw_path = imdb_dict['full_path']\n",
    "raw_age = imdb_dict['age']\n",
    "raw_gender = imdb_dict['gender']\n",
    "raw_sface = imdb_dict['second_face_score']\n",
    "\n",
    "age = []\n",
    "gender = []\n",
    "imgs = []\n",
    "for i, sface in enumerate(raw_sface):\n",
    "    if i%200000==0:\n",
    "        print(\"Processing {0} of {1}\".format(i,len(raw_sface)))\n",
    "#         display(Image(filename=raw_path[i]))\n",
    "        print(\"Second face score: {}\".format(sface), end=\" \")\n",
    "        print(\"Age: {}\".format(raw_age[i]), end=\" \")\n",
    "        print(\"Gender: {}\".format(raw_gender[i]))\n",
    "    if np.isnan(sface) and raw_age[i] >= 0 and not np.isnan(raw_gender[i]):\n",
    "        age.append(raw_age[i])\n",
    "        gender.append(raw_gender[i])\n",
    "        imgs.append(raw_path[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting images path to images.\n",
      "Original size: 460723 - Preprocess size: 100000\n"
     ]
    }
   ],
   "source": [
    "# Convert images path to images.\n",
    "\n",
    "# only take a subset of dataset: first 100000 imgs\n",
    "# dataset = np.ndarray(shape=(100000, img_size, img_size, img_depth), dtype=np.float32)\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"/pkl_folder/imdb_data_train.pkl\") and os.path.exists(\n",
    "    os.getcwd()+\"/pkl_folder/imdb_data_valid.pkl\") and os.path.exists(\n",
    "    os.getcwd()+\"pkl_folder/imdb_data_test.pkl\"):\n",
    "    print(\"Dataset already present - Skip convert images to images.\")\n",
    "else:\n",
    "    print(\"Converting images path to images.\")\n",
    "    real_imgs = []\n",
    "    tmp = []\n",
    "    for i, img_path in enumerate(imgs):\n",
    "        if i==100000:\n",
    "            break\n",
    "        tmp = np.asarray(spm.imresize(spm.imread(img_path, mode='RGB'), (128, 128, 3)), dtype=np.float32)\n",
    "        real_imgs.append(tmp)\n",
    "\n",
    "    print(\"Original size: {0} - Preprocess size: {1}\".format(len(raw_sface), len(real_imgs)))\n",
    "    \n",
    "#     print(\"Converting images path to images.\")\n",
    "#     for i, img_path in enumerate(imgs):\n",
    "#         if i == 100000:\n",
    "#             break\n",
    "#         image_data = resize(((ndimage.imread(img_path).astype(float) - img_depth / 2) / img_depth), \n",
    "#                             (img_size, img_size, img_depth), mode='reflect')\n",
    "#         dataset[i, :, :, :] = image_data\n",
    "\n",
    "#     print(\"Original size: {0} - Preprocess size: {1}\".format(len(raw_sface), len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = {'image_inputs': np.array(real_imgs[0:60000]),\n",
    "                'age_labels': np.array(age[0:60000]),\n",
    "                'gender_labels': np.array(gender[0:60000])\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_out = pickle.dumps(data_train, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_train.pkl\"),'wb') as f_out:\n",
    "    for idx in range(0, len(bytes_out), max_bytes):\n",
    "        f_out.write(bytes_out[idx:idx+max_bytes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_in = bytearray(0)\n",
    "input_size = os.path.getsize(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_train.pkl\"))\n",
    "with open(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_train.pkl\"), 'rb') as f_in:\n",
    "    for _ in range(0, input_size, max_bytes):\n",
    "        bytes_in += f_in.read(max_bytes)\n",
    "data2 = pickle.loads(bytes_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "img_depth = 3\n",
    "\n",
    "def dump_data()\n",
    "\n",
    "def create_pickle(force=False):\n",
    "    data_train_path = os.getcwd()+\"/pkl_folder/imdb_data_train.pkl\"\n",
    "    data_valid_path = os.getcwd()+\"/pkl_folder/imdb_data_valid.pkl\"\n",
    "    data_test_path = os.getcwd()+\"/pkl_folder/imdb_data_test.pkl\"\n",
    "    if os.path.exists(data_train_path) and os.path.exists(\n",
    "        data_valid_path) and os.path.exists(\n",
    "        data_test_path) and not force:\n",
    "        # You may override by setting force=True.\n",
    "        print(\"Dataset already present - Skip pickling.\")\n",
    "        \n",
    "    else:\n",
    "        # Dump data train\n",
    "        print('Dump data train')\n",
    "        data_train = {'image_inputs': np.array(real_imgs[0:60000]),\n",
    "                'age_labels': np.array(age[0:60000]),\n",
    "                'gender_labels': np.array(gender[0:60000])\n",
    "                }\n",
    "        print(\"Dataset train size: {}\".format(len(data_train['image_inputs'])))\n",
    "        bytes_out = pickle.dumps(data_train, pickle.HIGHEST_PROTOCOL)\n",
    "        with open(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_train.pkl\"),'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "#         with open(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_train.pkl\"),'wb') as f:\n",
    "#             pickle.dump(data_train, f)\n",
    "        print(\"Dataset train size: imdb_data_train.pkl\")\n",
    "\n",
    "        # Dump data valid\n",
    "        print('Dump data valid')\n",
    "        data_valid = {'image_inputs': np.array(real_imgs[60000:80000]),\n",
    "                'age_labels': np.array(age[60000:80000]),\n",
    "                'gender_labels': np.array(gender[60000:80000])\n",
    "                }\n",
    "        print(\"Dataset valid size: {}\".format(len(data_valid['image_inputs'])))\n",
    "        with open(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_valid.pkl\"),'wb') as f:\n",
    "            pickle.dump(data_valid, f)\n",
    "        print(\"Dataset train size: imdb_data_valid.pkl\")\n",
    "\n",
    "        # Dump data test\n",
    "        print('Dump data test')\n",
    "#         img_inputs = np.ndarray((len(real_imgs[80000:100000]), img_size, img_size, img_depth),\n",
    "#                                 buffer=real_imgs[80000:100000], dtype=np.float32)\n",
    "#         img_inputs = real_imgs[80000:100000]\n",
    "        data_test = {'image_inputs': np.array(real_imgs[80000:100000]),\n",
    "                'age_labels': np.array(age[80000:100000]),\n",
    "                'gender_labels': np.array(gender[80000:100000])\n",
    "                }\n",
    "        print(\"Dataset test size: {}\".format(len(data_test['image_inputs'])))\n",
    "        with open(os.path.join(os.getcwd(),\"pkl_folder/imdb_data_test.pkl\"),'wb') as f:\n",
    "            pickle.dump(data_test, f)\n",
    "        print(\"Dataset test size: imdb_data_test.pkl\")\n",
    "        \n",
    "    return data_train_path, data_valid_path, data_test_path\n",
    "\n",
    "data_train_path, data_valid_path, data_test_path = create_pickle(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            data_train = pickle.load(f)\n",
    "            labels = np.ndarray(len(data_train['image_inputs']), dtype=np.int32)\n",
    "            dataset = np.ndarray((len(data_train['image_inputs']), img_size, img_size, img_depth), dtype=np.float32)\n",
    "            # let's shuffle to have random dataset\n",
    "            np.random.shuffle(dataset)\n",
    "            dataset = data_train['image_inputs']\n",
    "            tmp_labels = []\n",
    "            for i, age_label in enumerate(data_train['age_labels']):\n",
    "                if age_label < 30:\n",
    "                    age = 0\n",
    "                elif age_label <= 45:\n",
    "                    age = 1\n",
    "                elif age_label < 60:\n",
    "                    age = 2\n",
    "                elif age_label >= 60:\n",
    "                    age = 3\n",
    "                else:\n",
    "                    continue\n",
    "                tmp = [age, data_train['gender_labels'][i]]\n",
    "                tmp_labels.append(tmp)\n",
    "            \n",
    "            labels = [tmp_labels]\n",
    "            return dataset, labels\n",
    "            \n",
    "    except Exception as e:\n",
    "        print('Unable to process data from', pickle_file, ':', e)\n",
    "        raise\n",
    "    return dataset, label\n",
    "\n",
    "train_dataset, train_labels = convert_label(data_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_train_path, 'rb') as f:\n",
    "    data_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([data_train['age_labels'], data_train['gender_labels']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp123 = []\n",
    "type(tmp123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        img_inputs = np.ndarray((len(real_imgs[0:60000]), img_size, img_size, img_depth), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(real_imgs[0].shape)\n",
    "print(img_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
